{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXVRSourSsu7",
        "outputId": "2977e160-e419-4b34-f03c-fc12911e1213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 🔧 Install YOLOv8 (Ultralytics)\n",
        "!pip install ultralytics --upgrade -q\n",
        "from ultralytics import YOLO\n",
        "import os, zipfile\n",
        "\n",
        "# 📁 Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 Unzip dataset\n",
        "# Ganti path ini dengan lokasi file ZIP kamu di Google Drive\n",
        "zip_path = \"/content/drive/MyDrive/archive.zip\"\n",
        "unzip_dir = \"/content/helmet_rompi\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_dir)\n"
      ],
      "metadata": {
        "id": "gSlY6XmITxuU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧾 Buat file konfigurasi YOLOv8\n",
        "# Pastikan struktur folder: /images/train, /images/val, /labels/train, /labels/val\n",
        "\n",
        "yaml_content = f\"\"\"\n",
        "train: {unzip_dir}/images/train\n",
        "val: {unzip_dir}/images/val\n",
        "\n",
        "nc: 2\n",
        "names: ['helmet', 'vest']\n",
        "\"\"\"\n",
        "\n",
        "with open(\"helmet_rompi.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n"
      ],
      "metadata": {
        "id": "QfeRQiJPUpXT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🏋️‍♂️ Train model YOLOv8\n",
        "# Gunakan model ringan agar cepat (yolov8n = nano)\n",
        "\n",
        "import os\n",
        "\n",
        "# Check if the validation path exists\n",
        "val_path = f\"{unzip_dir}/images/val\"\n",
        "if not os.path.exists(val_path):\n",
        "    print(f\"Error: Validation path not found at {val_path}. Please check your dataset structure and the path in helmet_rompi.yaml\")\n",
        "else:\n",
        "    model = YOLO(\"yolov8n.pt\")  # atau 'yolov8s.pt' jika GPU kuat\n",
        "    model.train(\n",
        "        data=\"helmet_rompi.yaml\",\n",
        "        epochs=50,\n",
        "        imgsz=640,\n",
        "        batch=16\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odyF4-SZUtXf",
        "outputId": "d6f8d239-4f2d-44fa-cf5b-40c53daaa3ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Validation path not found at /content/helmet_rompi/images/val. Please check your dataset structure and the path in helmet_rompi.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Evaluasi performa model\n",
        "metrics = model.val()\n",
        "print(\"mAP50:\", metrics.box.map50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG6D_gqQUv84",
        "outputId": "21936905-f6dc-4036-8fcd-764bdf9e15b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.151 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "WARNING ⚠️ Dataset 'coco.yaml' images not found, missing path '/content/datasets/coco/val2017.txt'\n",
            "Downloading https://ultralytics.com/assets/coco2017labels-segments.zip to '/content/datasets/coco2017labels-segments.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:01<00:00, 151MB/s]\n",
            "Unzipping /content/datasets/coco2017labels-segments.zip to /content/datasets/coco...: 100%|██████████| 122232/122232 [00:25<00:00, 4738.61file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://images.cocodataset.org/zips/train2017.zip to '/content/datasets/coco/images/train2017.zip'...\n",
            "Downloading http://images.cocodataset.org/zips/val2017.zip to '/content/datasets/coco/images/val2017.zip'...\n",
            "Downloading http://images.cocodataset.org/zips/test2017.zip to '/content/datasets/coco/images/test2017.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ✅ (554.0s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 14.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 37.9±12.1 MB/s, size: 139.7 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/labels/val2017... 4952 images, 48 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:18<00:00, 267.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco/labels/val2017.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [22:41<00:00,  4.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5000      36335      0.634      0.474      0.521      0.372\n",
            "                person       2693      10777      0.755      0.671      0.745      0.515\n",
            "               bicycle        149        314       0.69      0.392      0.457      0.264\n",
            "                   car        535       1918      0.649      0.514      0.562      0.365\n",
            "            motorcycle        159        367      0.715       0.58      0.659      0.414\n",
            "              airplane         97        143      0.814      0.764      0.834      0.653\n",
            "                   bus        189        283      0.747      0.643      0.739       0.62\n",
            "                 train        157        190      0.798       0.77      0.833      0.647\n",
            "                 truck        250        414      0.547      0.397      0.435      0.295\n",
            "                  boat        121        424      0.583        0.3      0.376       0.21\n",
            "         traffic light        191        634      0.647      0.345      0.409      0.212\n",
            "          fire hydrant         86        101       0.85      0.703      0.774      0.615\n",
            "             stop sign         69         75      0.696       0.64      0.692      0.631\n",
            "         parking meter         37         60      0.633        0.5      0.558      0.441\n",
            "                 bench        235        411      0.571      0.258      0.296      0.194\n",
            "                  bird        125        427      0.693      0.358      0.427      0.277\n",
            "                   cat        184        202      0.776      0.824      0.856      0.652\n",
            "                   dog        177        218      0.656      0.698      0.728      0.593\n",
            "                 horse        128        272      0.701      0.651      0.693      0.525\n",
            "                 sheep         65        354      0.611      0.667      0.662       0.46\n",
            "                   cow         87        372      0.697        0.6      0.682       0.49\n",
            "              elephant         89        252      0.705      0.833      0.821      0.629\n",
            "                  bear         49         71      0.848      0.775      0.841      0.688\n",
            "                 zebra         85        266      0.809      0.797      0.882      0.658\n",
            "               giraffe        101        232      0.857      0.828      0.887      0.684\n",
            "              backpack        228        371       0.49      0.156      0.198      0.101\n",
            "              umbrella        174        407      0.632      0.504      0.542      0.361\n",
            "               handbag        292        540       0.48      0.126      0.169     0.0859\n",
            "                   tie        145        252      0.688      0.361      0.429      0.269\n",
            "              suitcase        105        299      0.571      0.435      0.503      0.343\n",
            "               frisbee         84        115      0.747      0.771      0.767      0.584\n",
            "                  skis        120        241      0.605      0.317       0.37      0.189\n",
            "             snowboard         49         69      0.507      0.333      0.396      0.268\n",
            "           sports ball        169        260      0.716      0.438      0.473      0.332\n",
            "                  kite         91        327      0.606       0.52      0.558       0.38\n",
            "          baseball bat         97        145      0.586      0.386      0.403      0.219\n",
            "        baseball glove        100        148       0.67      0.473      0.512      0.303\n",
            "            skateboard        127        179      0.717      0.607      0.661       0.45\n",
            "             surfboard        149        267      0.629      0.476      0.507      0.309\n",
            "         tennis racket        167        225      0.705      0.618      0.671      0.398\n",
            "                bottle        379       1013      0.614      0.386      0.455      0.298\n",
            "            wine glass        110        341      0.661      0.352       0.42       0.27\n",
            "                   cup        390        895      0.584      0.441      0.489      0.351\n",
            "                  fork        155        215      0.582      0.318      0.389      0.263\n",
            "                 knife        181        325      0.508      0.163      0.173      0.106\n",
            "                 spoon        153        253      0.413      0.145       0.16     0.0987\n",
            "                  bowl        314        623       0.59      0.494       0.53      0.392\n",
            "                banana        103        370      0.551      0.319      0.373      0.234\n",
            "                 apple         76        236      0.415      0.242      0.227      0.156\n",
            "              sandwich         98        177      0.571      0.486      0.463      0.349\n",
            "                orange         85        285       0.44      0.418      0.369      0.281\n",
            "              broccoli         71        312      0.477      0.338      0.369      0.209\n",
            "                carrot         81        365      0.447      0.293      0.307      0.189\n",
            "               hot dog         51        125       0.76      0.431      0.497      0.364\n",
            "                 pizza        153        284       0.66      0.613      0.658      0.503\n",
            "                 donut         62        328      0.577      0.494      0.515      0.408\n",
            "                  cake        124        310      0.535       0.39      0.437      0.293\n",
            "                 chair        580       1771      0.583      0.339      0.403      0.257\n",
            "                 couch        195        261      0.592      0.548      0.585      0.434\n",
            "          potted plant        172        342      0.521       0.38      0.385      0.226\n",
            "                   bed        149        163      0.551      0.552      0.589      0.428\n",
            "          dining table        501        695      0.528      0.439      0.435      0.293\n",
            "                toilet        149        179      0.718      0.737      0.774      0.641\n",
            "                    tv        207        288      0.772      0.635      0.714      0.554\n",
            "                laptop        183        231      0.682      0.662        0.7      0.579\n",
            "                 mouse         88        106      0.631      0.642      0.709      0.533\n",
            "                remote        145        283      0.431      0.223      0.271      0.161\n",
            "              keyboard        106        153      0.594      0.602      0.649      0.482\n",
            "            cell phone        214        262      0.551      0.351      0.398       0.28\n",
            "             microwave         54         55      0.617      0.545      0.643      0.514\n",
            "                  oven        115        143      0.644      0.448      0.511       0.35\n",
            "               toaster          8          9      0.727      0.222      0.436      0.316\n",
            "                  sink        187        225       0.56       0.44      0.507      0.337\n",
            "          refrigerator        101        126      0.667      0.587       0.65      0.511\n",
            "                  book        230       1129      0.491      0.111      0.197     0.0973\n",
            "                 clock        204        267      0.751      0.607      0.667      0.459\n",
            "                  vase        137        274      0.584      0.445      0.453      0.322\n",
            "              scissors         28         36       0.69      0.333      0.332      0.278\n",
            "            teddy bear         94        190       0.67      0.558      0.604      0.419\n",
            "            hair drier          9         11          1          0    0.00494    0.00377\n",
            "            toothbrush         34         57      0.403      0.193      0.236      0.165\n",
            "Speed: 5.7ms preprocess, 249.5ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
            "Saving runs/detect/val/predictions.json...\n",
            "\n",
            "Evaluating pycocotools mAP using runs/detect/val/predictions.json and /content/datasets/coco/annotations/instances_val2017.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.75s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=4.32s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=83.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=18.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.654\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "mAP50: 0.5211504117075794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_content = f\"\"\"\n",
        "train: {unzip_dir}/images/train\n",
        "val: {unzip_dir}/images/val\n",
        "\n",
        "nc: 2\n",
        "names: ['helmet', 'vest']\n",
        "\"\"\"\n",
        "\n",
        "with open(\"helmet_rompi.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S8KxB0mRUxkQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Coba ambil gambar dari val, jika tidak ada, ambil dari train\n",
        "image_path = \"\"\n",
        "val_images = glob.glob(f\"{unzip_dir}/images/val/*.jpg\")\n",
        "if val_images:\n",
        "    image_path = val_images[0]\n",
        "else:\n",
        "    train_images = glob.glob(f\"{unzip_dir}/images/train/*.jpg\")\n",
        "    if train_images:\n",
        "        image_path = train_images[0]\n",
        "\n",
        "# Lakukan prediksi jika gambar ditemukan\n",
        "if image_path:\n",
        "    result = model.predict(source=image_path, conf=0.4, show=True)\n",
        "else:\n",
        "    print(\"❌ Tidak ditemukan gambar di /val atau /train.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwTIlnU4gNqn",
        "outputId": "5446a4f1-229a-4166-cccb-d637c8b01516"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Tidak ditemukan gambar di /val atau /train.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 💾 Simpan model terlatih\n",
        "model.export(format=\"torchscript\")  # or choose another valid format from the error message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "WqvVGts-U0aO",
        "outputId": "61cb8b28-067a-47ee-a8ed-1152125e417b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.151 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "💡 ProTip: Export to OpenVINO format for best performance on Intel CPUs. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.6.0+cu124...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 3.9s, saved as 'yolov8n.torchscript' (12.5 MB)\n",
            "\n",
            "Export complete (4.6s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8n.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov8n.torchscript imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yolov8n.torchscript'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}